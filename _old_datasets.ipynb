{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders for CUB Birds, Stanford Dogs, Foodx datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.io #for dogs dateset\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUB-200-2011 (Birds) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUBDataset(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"\n",
    "    Dataset class for CUB Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_root_path, caption_root_path=None, split=\"train\", *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_root_path:      path to dir containing images and lists folders\n",
    "            caption_root_path:    path to dir containing captions\n",
    "            split:          train / test\n",
    "            *args:\n",
    "            **kwargs:\n",
    "        \"\"\"\n",
    "        image_info = self.get_file_content(f\"{image_root_path}/images.txt\")\n",
    "        self.image_id_to_name = {y[0]: y[1] for y in [x.strip().split(\" \") for x in image_info]}\n",
    "        split_info = self.get_file_content(f\"{image_root_path}/train_test_split.txt\")\n",
    "        self.split_info = {self.image_id_to_name[y[0]]: y[1] for y in [x.strip().split(\" \") for x in split_info]}\n",
    "        self.split = \"1\" if split == \"train\" else \"0\"\n",
    "        self.caption_root_path = caption_root_path\n",
    "\n",
    "        super(CUBDataset, self).__init__(root=f\"{image_root_path}/images\", is_valid_file=self.is_valid_file,\n",
    "                                         *args, **kwargs)\n",
    "\n",
    "    def is_valid_file(self, x):\n",
    "        return self.split_info[(x[len(self.root) + 1:])] == self.split\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_content(file_path):\n",
    "        with open(file_path) as fo:\n",
    "            content = fo.readlines()\n",
    "        return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford Dogs Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DOGDataset(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"\n",
    "    Dataset class for DOG Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_root_path, caption_root_path=None, split=\"train\", *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_root_path:      path to dir containing images and lists folders\n",
    "            caption_root_path:    path to dir containing captions\n",
    "            split:          train / test\n",
    "            *args:\n",
    "            **kwargs:\n",
    "        \"\"\"\n",
    "        image_info = self.get_file_content(f\"{image_root_path}splits/file_list.mat\")\n",
    "        image_files = [o[0][0] for o in image_info]\n",
    "        \n",
    "        split_info = self.get_file_content(f\"{image_root_path}/splits/{split}_list.mat\")\n",
    "        split_files = [o[0][0] for o in split_info]\n",
    "        self.split_info = {}\n",
    "        if split == 'train' :\n",
    "            for image in image_files:\n",
    "                if image in split_files:\n",
    "                    self.split_info[image] = \"1\"\n",
    "                else:\n",
    "                    self.split_info[image] = \"0\"\n",
    "        elif split== 'test' :\n",
    "            for image in image_files:\n",
    "                if image in split_files:\n",
    "                    self.split_info[image] = \"0\"\n",
    "                else:\n",
    "                    self.split_info[image] = \"1\"\n",
    "                    \n",
    "        self.split = \"1\" if split == \"train\" else \"0\"\n",
    "        self.caption_root_path = caption_root_path\n",
    "\n",
    "        super(DOGDataset, self).__init__(root=f\"{image_root_path}Images\", is_valid_file = self.is_valid_file,\n",
    "                                         *args, **kwargs)\n",
    "\n",
    "    def is_valid_file(self, x):\n",
    "        return self.split_info[(x[len(self.root) + 1:])] == self.split\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_content(file_path):\n",
    "        content =  scipy.io.loadmat(file_path)\n",
    "        return content['file_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FoodX-251 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FOODDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, *args, **kwargs):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        # return (\n",
    "        #     torchvision.transforms.functional.to_tensor(Image.open(row[\"path\"])), row['label']\n",
    "        # )\n",
    "        #print(row[\"path\"])\n",
    "    \n",
    "        img = Image.open(row[\"path\"])\n",
    "        img2 = img.resize((224,224), resample=0)\n",
    "        #img2.save('/home/u20020067/Downloads/1.jpg')\n",
    "\n",
    "        out = T.ToTensor()(img2)\n",
    "        #print(out.shape)\n",
    "\n",
    "        #out = F.interpolate(img, size=224)  #The resize operation on tensor.\n",
    "        #print(out)\n",
    "\n",
    "        #x = self.transform(Image.open(row[\"path\"]))\n",
    "        #print(out)\n",
    "        # x = F.interpolate(x, (224, 224))\n",
    "\n",
    "        #x = torchvision.transforms.functional.to_tensor(x)\n",
    "  \n",
    "        return out, row['label']\n",
    "\n",
    "    # transform = T.Compose([\n",
    "    #     T.ToTensor(),\n",
    "    #     T.ToPILImage(),\n",
    "    #     T.Resize(224),\n",
    "    #     T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FOODDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, dataframe, *args, **kwargs):\n",
    "#         self.dataframe = dataframe\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataframe)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         row = self.dataframe.iloc[index]\n",
    "#         # return (\n",
    "#         #     torchvision.transforms.functional.to_tensor(Image.open(row[\"path\"])), row['label']\n",
    "#         # )\n",
    "#         #print(row[\"path\"])\n",
    "    \n",
    "#         img = Image.open(row[\"path\"])\n",
    "#         img2 = img.resize((224,224), resample=0)\n",
    "#         #img2.save('/home/u20020067/Downloads/1.jpg')\n",
    "\n",
    "#         out = T.ToTensor()(img2)\n",
    "#         #print(out.shape)\n",
    "\n",
    "#         #out = F.interpolate(img, size=224)  #The resize operation on tensor.\n",
    "#         #print(out)\n",
    "\n",
    "#         #x = self.transform(Image.open(row[\"path\"]))\n",
    "#         #print(out)\n",
    "#         # x = F.interpolate(x, (224, 224))\n",
    "\n",
    "#         #x = torchvision.transforms.functional.to_tensor(x)\n",
    "  \n",
    "#         return out, row['label']\n",
    "\n",
    "#     # transform = T.Compose([\n",
    "#     #     T.ToTensor(),\n",
    "#     #     T.ToPILImage(),\n",
    "#     #     T.Resize(224),\n",
    "#     #     T.ToTensor()])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ec74bd9cb25c7f3d818fc24baee49db9b312a136e1d154714bc57dce796a060"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('cv703': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}