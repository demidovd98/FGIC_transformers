{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV-703, Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from models_to_finetune import deit_small_patch16_224, deit_base_patch16_224, resnet50\n",
    "\n",
    "from datasets import CUBDataset, DOGDataset, FOODDataset\n",
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# from __future__ import print_function, division\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch.optim import lr_scheduler\n",
    "\n",
    "# import torchvision\n",
    "# from torchvision import datasets, models, transforms\n",
    "# import torchvision.transforms as T\n",
    "\n",
    "# from PIL import Image\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# import scipy.io #for dogs dateset\n",
    "\n",
    "# import time\n",
    "# import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup a dataset\n",
    "Uncomment that one dataset you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUB-200-2011 (Birds): Dataset (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_number = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/apps/local/shared/CV703/datasets/CUB/CUB_200_2011/\"\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "# Write data transform here as per the requirement\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "train_dataset = CUBDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"train\")\n",
    "test_dataset = CUBDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"test\")\n",
    "print('Number of train samples:', len(train_dataset))\n",
    "print('Number of test samples:', len(test_dataset))\n",
    "\n",
    "\n",
    "# Load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, drop_last=True, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, drop_last=False, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford Dogs: Dataset (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_number = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/apps/local/shared/CV703/datasets/dog/\"\n",
    "\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "\n",
    "train_dataset = DOGDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"train\")\n",
    "test_dataset = DOGDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"test\")\n",
    "print('Number of train samples:', len(train_dataset))\n",
    "print('Number of test samples:', len(test_dataset))\n",
    "\n",
    "# Load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, drop_last=True, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, labels) in enumerate(test_loader):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUB-200-2011 + Stanford Dog: concatenated Dataset (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_number = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUB:\n",
    "data_root_bird = \"/apps/local/shared/CV703/datasets/CUB/CUB_200_2011/\"\n",
    "\n",
    "mean_bird = (0.485, 0.456, 0.406)\n",
    "std_bird = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "# write data transform here as per the requirement\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean_bird, std=std_bird)\n",
    "    ])\n",
    "\n",
    "train_dataset_cub = CUBDataset(image_root_path=f\"{data_root_bird}\", transform=data_transform, split=\"train\")\n",
    "test_dataset_cub = CUBDataset(image_root_path=f\"{data_root_bird}\", transform=data_transform, split=\"test\")\n",
    "print('Number of train samples:', len(train_dataset_cub))\n",
    "print('Number of test samples:', len(test_dataset_cub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dog:\n",
    "mean_dog = (0.485, 0.456, 0.406)\n",
    "std_dog = (0.229, 0.224, 0.225)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean_dog, std=std_dog)\n",
    "    ])\n",
    "\n",
    "\n",
    "data_root_dog = \"/apps/local/shared/CV703/datasets/dog/\"\n",
    "\n",
    "# TODO: Start labels counting from 200 (in case of concatenation only)!\n",
    "train_dataset_dog = DOGDataset(image_root_path=f\"{data_root_dog}\", transform=data_transform, split=\"train\")\n",
    "test_dataset_dog = DOGDataset(image_root_path=f\"{data_root_dog}\", transform=data_transform, split=\"test\")\n",
    "print('Number of train samples:', len(train_dataset_dog))\n",
    "print('Number of test samples:', len(test_dataset_dog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated dataloader for CUB and DOG\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "             torch.utils.data.ConcatDataset([train_dataset_cub, train_dataset_dog]),\n",
    "             batch_size=32, shuffle=True,\n",
    "             num_workers=1, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "             torch.utils.data.ConcatDataset([test_dataset_cub, test_dataset_dog]),\n",
    "             batch_size=32, shuffle=True,\n",
    "             num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset_cub), len(train_dataset_dog), len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset_cub), len(test_dataset_dog), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, targets) in enumerate(train_loader):\n",
    "\n",
    "    print('image :: ', inputs.shape)\n",
    "    print(targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FoodX-251 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_number = 251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_type = \"local\" # comment out if using ds from the shared folder\n",
    "#ds_type = \"shared\" # comment out if using ds from the local folder\n",
    "\n",
    "\n",
    "if (ds_type == \"local\"):\n",
    "    data_dir = \"/home/dmitry.demidov/Documents/Datasets/FoodX-251\"\n",
    "\n",
    "    split = 'train'\n",
    "    train_df = pd.read_csv(f'{data_dir}/annot/{split}_info.csv', names= ['image_name','label'])\n",
    "    train_df['path'] = train_df['image_name'].map(lambda x: os.path.join(f'{data_dir}/{split}/{split}_set/', x))\n",
    "\n",
    "    split = 'val'\n",
    "    test_df = pd.read_csv(f'{data_dir}/annot/{split}_info.csv', names= ['image_name','label'])\n",
    "    test_df['path'] = test_df['image_name'].map(lambda x: os.path.join(f'{data_dir}/{split}/{split}_set/', x))\n",
    "\n",
    "elif (ds_type == \"shared\"):\n",
    "    data_dir = \"/apps/local/shared/CV703/datasets/FoodX/food_dataset\"\n",
    "\n",
    "    split = 'train'\n",
    "    train_df = pd.read_csv(f'{data_dir}/annot/{split}_info.csv', names= ['image_name','label'])\n",
    "    train_df['path'] = train_df['image_name'].map(lambda x: os.path.join(f'{data_dir}/{split}_set/', x))\n",
    "\n",
    "    split = 'val'\n",
    "    test_df = pd.read_csv(f'{data_dir}/annot/{split}_info.csv', names= ['image_name','label'])\n",
    "    test_df['path'] = test_df['image_name'].map(lambda x: os.path.join(f'{data_dir}/{split}_set/', x))\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Choose dataset type (local/shared)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 118475\n",
      "Number of test samples: 11994\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FOODDataset(train_df)\n",
    "test_dataset = FOODDataset(test_df)\n",
    "print('Number of train samples:', len(train_dataset))\n",
    "print('Number of test samples:', len(test_dataset))\n",
    "\n",
    "# load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, drop_last=True, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, drop_last=False, shuffle=True) # Not enough memory for more than 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118475 11994\n",
      "925 375\n",
      "torch.Size([128, 3, 224, 224])\n",
      "tensor([161, 187, 211,  78, 229, 221,  93, 221, 123, 182, 157,  52, 177,  41,\n",
      "        130, 110, 235,  48,  40,  77,  74,  60,   0, 177, 219, 222, 152, 216,\n",
      "        104,  16, 173,  40,  41, 241,  41, 135, 226, 185, 168, 207,  48, 230,\n",
      "         50, 219, 171,  71,  58,  53, 179, 193, 236, 232, 214, 172,  14,  35,\n",
      "         50, 215,   2,  16,  88,  63, 145,  98, 232, 112, 127, 227,  22, 112,\n",
      "        148, 203, 152,  20, 136,  91, 101, 169, 145, 232, 125, 206, 138,  27,\n",
      "        141, 119, 111, 239,  64, 175, 222,  20, 123,  73, 211, 137,  45, 172,\n",
      "        202, 235, 246,  60,  98, 177, 229, 195, 167, 138,  75, 197, 237,  86,\n",
      "        146, 113,  44, 208, 141, 231,  89,  21,  47, 176,  53,  94,   8,  10,\n",
      "        134, 231])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the dataset:\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "\n",
    "print(len(train_loader), len(test_loader))\n",
    "\n",
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ViT for transfer learning (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # we will use only the last class token (produced by the last block) for transfer learning\n",
    "# model = deit_base_patch16_224(pretrained=True, use_top_n_heads=8,use_patch_outputs=False).cuda()\n",
    "\n",
    "# # freeze backbone and add linear classifier on top that\n",
    "# # for param in model.parameters():\n",
    "# #     param.requires_grad = True # False\n",
    "# model.head = torch.nn.Linear(in_features=model.head.in_features, out_features=classes_number)\n",
    "\n",
    "# model.head.apply(model._init_weights)\n",
    "# # for param in model.head.parameters():\n",
    "# #     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.003, betas=(0.5, 0.999))\n",
    "\n",
    "# #model.train()\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 100\n",
    "# print('Training....')\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     epoch_loss = 0.0\n",
    "#     epoch_acc = 0.0\n",
    "#     #running_loss = 0.0\n",
    "\n",
    "#     with tqdm(train_loader) as p_bar:\n",
    "#         for samples, targets in p_bar:\n",
    "#             samples = samples.to(device)\n",
    "#             targets = targets.to(device)\n",
    "            \n",
    "#             outputs = model(samples) #, fine_tune=False)\n",
    "#             loss = criterion(outputs, targets)\n",
    "\n",
    "#             loss_value = loss.item()\n",
    "#             if not math.isfinite(loss_value):\n",
    "#                 print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "#                 sys.exit(1)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             epoch_loss += outputs.shape[0] * loss.item()\n",
    "\n",
    "#             epoch_acc += torch.sum(outputs.argmax(dim=-1) == targets).item()\n",
    "\n",
    "#             # print statistics\n",
    "#             #running_loss += loss.item()\n",
    "\n",
    "#     # if i % 100 == 99:    # print every 10 mini-batches\n",
    "#     #     print('[%d, %5d] loss: %.3f' %\n",
    "#     # (epoch + 1, i + 1, running_loss / 100))\n",
    "#     # running_loss = 0.0\n",
    "\n",
    "\n",
    "#     loss = epoch_loss / len(train_dataset)\n",
    "#     acc = epoch_acc / len(train_dataset)\n",
    "\n",
    "\n",
    "#     # print statistics\n",
    "#     print(\"Epoch:\", epoch+1, \"|\", \"Loss:\", loss,\n",
    "#         'Instant Accuracy:{0:.3%}'.format(acc))\n",
    "\n",
    "#     f = open(\"./models/statistics.txt\", \"a\")\n",
    "#     f.write(\"Epoch: \" + str(epoch) + \", \" +\"Loss: \"+ str(loss) + \", \"+\"Accuracy: \"+ str(acc) + \"\\n\")\n",
    "#     f.close()\n",
    "    \n",
    "#     torch.save({'state_dict': model.state_dict()}, './models/model_{0}ep_{1:.1}loss_{2:.3}acc.pt'.format(epoch, loss, acc,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training + Evaluation (in parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test funcs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, model, criterion, optimizer, train_dataset, train_loader, epoch, resnet=False):\n",
    "    print('Training....')\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    acc=0.0\n",
    "\n",
    "    with tqdm(train_loader) as p_bar:\n",
    "        for samples, targets in p_bar:\n",
    "            samples = samples.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            if resnet:\n",
    "                outputs = model(samples)\n",
    "            else:\n",
    "                outputs = model(samples, fine_tune=True)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss_value = loss.item()\n",
    "            if not math.isfinite(loss_value):\n",
    "                print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "                sys.exit(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += outputs.shape[0] * loss.item()\n",
    "\n",
    "            acc+=torch.sum(outputs.argmax(dim=-1) == targets).item()\n",
    "\n",
    "    loss_print = epoch_loss / len(train_dataset)\n",
    "    acc_print = acc/len(train_dataset)\n",
    "    epoch_print = epoch+1\n",
    "\n",
    "    print(\"Epoch:\", epoch_print, \"|\", \"Loss:\", loss_print)\n",
    "    print(\"Train Accuracy:{0:.3%}\".format(acc_print))\n",
    "\n",
    "    f = open(\"./models/statistics.txt\", \"a\")\n",
    "    text_train = \"Epoch: \" + str(epoch_print) + \", \" + \"Train Loss: \" + str(loss_print) + \", \" + \"Train Accuracy: \" + str(acc_print) + \"\\n\"\n",
    "    f.write(text_train)\n",
    "    f.close()\n",
    "    \n",
    "    torch.save({'state_dict': model.state_dict()}, './models/model_{0}ep_{1:.2}loss.pt'.format(epoch_print, loss_print))\n",
    "\n",
    "    sent_results(text=text_train)\n",
    "\n",
    "    #del samples\n",
    "    #del targets\n",
    "\n",
    "\n",
    "\n",
    "def test(device, model, criterion, test_dataset, test_loader, model_path = './folder/path.pt', test_only = False, resnet=False):\n",
    "    print('Testing....')\n",
    "\n",
    "    if test_only:\n",
    "        print('Test only!')\n",
    "        state_dict = torch.load(model_path)['state_dict']\n",
    "        model.load_state_dict(state_dict)\n",
    "        model = model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    acc=0.0\n",
    "\n",
    "    with tqdm(test_loader) as p_bar:\n",
    "        for samples, targets in p_bar:\n",
    "            samples = samples.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            if resnet:\n",
    "                outputs = model(samples)\n",
    "            else:\n",
    "                outputs = model(samples, fine_tune=False)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            epoch_loss += outputs.shape[0] * loss.item()\n",
    "\n",
    "            acc+=torch.sum(outputs.argmax(dim=-1) == targets).item()\n",
    "\n",
    "    acc_print = acc/len(test_dataset)\n",
    "    loss_print = epoch_loss / len(test_dataset)\n",
    "\n",
    "    print(\"Test Loss:\", loss_print)\n",
    "    print('Test Accuracy:{0:.3%}'.format(acc_print))\n",
    "\n",
    "    f = open(\"./models/statistics.txt\", \"a\")\n",
    "    text_test = \"Test Loss: \"+ str(loss_print) + \", \" + \"Test Accuracy: \" + str(acc_print) + \"\\n\" + \"\\n\"\n",
    "    f.write(text_test)\n",
    "    f.close()\n",
    "\n",
    "    sent_results(text=text_test)\n",
    "\n",
    "    #del samples\n",
    "    #del targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send results to an email (optional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Email sent successfully!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import sent_results\n",
    "\n",
    "# Test:\n",
    "sent_results(text='Start')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=[])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=9216, out_features=251, bias=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deit_base_patch16_224(pretrained=True, use_top_n_heads=12,use_patch_outputs=False) #.cuda()\n",
    "#model = deit_small_patch16_224(pretrained=True, use_top_n_heads=8,use_patch_outputs=False).cuda()\n",
    "\n",
    "# # Freeze backbone:\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = True # original: False\n",
    "\n",
    "# Add linear classifier on top:\n",
    "model.head = torch.nn.Linear(in_features=model.head.in_features, out_features=classes_number)\n",
    "model.head.apply(model._init_weights)\n",
    "# for param in model.head.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=251, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# def init_weights(m):\n",
    "#     if isinstance(m, torch.nn.Linear):\n",
    "#         torch.nn.init.xavier_uniform_(m.weight)\n",
    "#         m.bias.data.fill_(0.01)\n",
    "\n",
    "model = models.resnet50(pretrained=True) #.cuda()\n",
    "model.fc = torch.nn.Linear(in_features=model.fc.in_features, out_features=classes_number, bias=True)\n",
    "#model.fc.apply(init_weights)\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True # original: False\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionResnetV2(\n",
      "  (conv2d_1a): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (conv2d_2a): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (conv2d_2b): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2d_3b): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (conv2d_4a): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (maxpool_5a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (mixed_5b): Mixed_5b(\n",
      "    (branch0): BasicConv2d(\n",
      "      (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (branch1): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (2): BasicConv2d(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (repeat): Sequential(\n",
      "    (0): Block35(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): Block35(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block35(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): Block35(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): Block35(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): Block35(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (6): Block35(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (7): Block35(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (8): Block35(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (9): Block35(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (mixed_6a): Mixed_6a(\n",
      "    (branch0): BasicConv2d(\n",
      "      (conv): Conv2d(320, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (branch1): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (2): BasicConv2d(\n",
      "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (repeat_1): Sequential(\n",
      "    (0): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (6): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (7): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (8): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (9): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (10): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (11): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (12): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (13): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (14): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (15): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (16): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (17): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (18): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (19): Block17(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (mixed_7a): Mixed_7a(\n",
      "    (branch0): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (branch1): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 288, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(1088, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (2): BasicConv2d(\n",
      "        (conv): Conv2d(288, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (repeat_2): Sequential(\n",
      "    (0): Block8(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): Block8(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block8(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): Block8(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): Block8(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): Block8(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (6): Block8(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (7): Block8(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (8): Block8(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (block8): Block8(\n",
      "    (branch0): BasicConv2d(\n",
      "      (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (branch1): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (2): BasicConv2d(\n",
      "        (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (conv2d_7b): BasicConv2d(\n",
      "    (conv): Conv2d(2080, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (classif): Linear(in_features=1536, out_features=251, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "import timm\n",
    "\n",
    "model = timm.create_model('inception_resnet_v2', pretrained=True, num_classes=classes_number) #.cuda()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True # original: False\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training + validation in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/462 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'fine_tune'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3291678/3023498446.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     train (device=device, model=model, criterion=criterion, optimizer=optimizer, \n\u001b[0m\u001b[1;32m      9\u001b[0m         train_dataset=train_dataset, train_loader=train_loader, epoch=epoch)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3291678/1197654332.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(device, model, criterion, optimizer, train_dataset, train_loader, epoch, resnet)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfine_tune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cv703/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'fine_tune'"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train (device=device, model=model, criterion=criterion, optimizer=optimizer, \n",
    "        train_dataset=train_dataset, train_loader=train_loader, epoch=epoch)\n",
    "\n",
    "    test (device=device, model=model, criterion=criterion, \n",
    "        test_dataset=test_dataset, test_loader=test_loader, test_only = False) #, model_path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/925 [00:00<?, ?it/s]/home/dmitry.demidov/.conda/envs/cv703/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 925/925 [22:44<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 3.072274742665787\n",
      "Train Accuracy:35.316%\n",
      "Testing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:10<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.8167234339753011\n",
      "Test Accuracy:55.561%\n",
      "Training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [22:35<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss: 1.7861448842982597\n",
      "Train Accuracy:57.653%\n",
      "Testing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:09<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5666793703297406\n",
      "Test Accuracy:60.839%\n",
      "Training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [22:30<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss: 1.2214946277213514\n",
      "Train Accuracy:69.502%\n",
      "Testing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:11<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5586477812675907\n",
      "Test Accuracy:61.364%\n",
      "Training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [22:21<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss: 0.8223244413692605\n",
      "Train Accuracy:78.790%\n",
      "Testing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:09<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.6454278050173476\n",
      "Test Accuracy:60.022%\n",
      "Training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 43/925 [01:02<21:28,  1.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_270233/699871144.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     train (device=device, model=model, criterion=criterion, optimizer=optimizer, \n\u001b[0m\u001b[1;32m      9\u001b[0m         train_dataset=train_dataset, train_loader=train_loader, epoch=epoch, resnet=True)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_270233/1197654332.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(device, model, criterion, optimizer, train_dataset, train_loader, epoch, resnet)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cv703/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cv703/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cv703/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    108\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cv703/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train (device=device, model=model, criterion=criterion, optimizer=optimizer, \n",
    "        train_dataset=train_dataset, train_loader=train_loader, epoch=epoch, resnet=True)\n",
    "\n",
    "    test (device=device, model=model, criterion=criterion, \n",
    "        test_dataset=test_dataset, test_loader=test_loader, test_only = False, resnet=True) #, model_path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "class MyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cnn, deit):\n",
    "\n",
    "        super(MyModel,self).__init__()\n",
    "\n",
    "        #self.cnn = timm.create_model('inception_resnet_v2', pretrained=True, num_classes=classes_number).cuda()\n",
    "        \n",
    "        self.cnn = cnn\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False # original: False\n",
    "        \n",
    "        self.cnn.fc = torch.nn.Linear(in_features=self.cnn.fc.in_features, out_features=1024, bias=True)\n",
    "        #model.fc.apply(init_weights)\n",
    "        for param in self.cnn.fc.parameters():\n",
    "            param.requires_grad = True # original: False\n",
    "\n",
    "        print(self.cnn)\n",
    "\n",
    "\n",
    "        #resnet = models.resnet50(pretrained=True)\n",
    "        #resnet_features = resnet.fc.in_features\n",
    "\n",
    "        #torch.nn.Sequential(*(list(cnn.children())[:-1]))\n",
    "        # self.cnn.fc = torch.nn.Linear(\n",
    "        #     self.cnn.fc.in_features, 20)\n",
    "\n",
    "        #transformer = deit_base_patch16_224(pretrained=True, use_top_n_heads=10,use_patch_outputs=False)\n",
    "        #transformer_features = transformer.head.in_features\n",
    "\n",
    "\n",
    "        #self.deit = deit_base_patch16_224(pretrained=True, use_top_n_heads=10,use_patch_outputs=False).cuda()\n",
    "        #model = deit_small_patch16_224(pretrained=True, use_top_n_heads=8,use_patch_outputs=False).cuda()\n",
    "        \n",
    "        self.deit = deit\n",
    "        # Freeze backbone:\n",
    "        for param in self.deit.parameters():\n",
    "            param.requires_grad = False # original: False\n",
    "\n",
    "        self.deit.head = torch.nn.Linear(in_features=self.deit.head.in_features, out_features=1024)\n",
    "        self.deit.head.apply(self.deit._init_weights)\n",
    "        # Unfreeze linear classifier on top:\n",
    "        for param in self.deit.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        print(self.deit)\n",
    "\n",
    "        #self.deit = deit\n",
    "        #torch.nn.Sequential(*(list(deit.children())[:-1]))\n",
    "\n",
    "\n",
    "        # self.deit.head = torch.nn.Linear(in_features=self.deit.head.in_features, out_features=classes_number)\n",
    "        # self.deit.head.apply(model._init_weights)\n",
    "        \n",
    "        # for param in model.head.parameters():\n",
    "        #     param.requires_grad = True\n",
    "\n",
    "        # for name,param in cnn.named_parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        # for name,param in deit.named_parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "\n",
    "        # for param in self.cnn.parameters():\n",
    "        #     param.requires_grad = False # original: False\n",
    "\n",
    "        # for param in self.deit.parameters():\n",
    "        #     param.requires_grad = False # original: False\n",
    "\n",
    "\n",
    "        # self.resnet_mlp = torch.nn.Linear(in_features=resnet_features, out_features=1024)\n",
    "        # self.transformer_mlp = torch.nn.Linear(in_features=1000, out_features=1024)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(in_features=2048, out_features=251)\n",
    "\n",
    "        #self.fc2 = torch.nn.Linear(4096, 251)\n",
    "\n",
    "        self.drop = torch.nn.Dropout(p=0.3)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        cnn_out = self.cnn(x)\n",
    "        #print(cnn_out.shape)\n",
    "\n",
    "        deit_out = self.deit(x, fine_tune=False)\n",
    "        #print(deit_out.shape)\n",
    "\n",
    "        concat = torch.cat((cnn_out, deit_out), dim=1)\n",
    "\n",
    "        out = self.fc1(concat)\n",
    "\n",
    "        #out = self.drop(out)\n",
    "        #out = torch.nn.F.relu(out)\n",
    "\n",
    "        #out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=[])\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1024, bias=True)\n",
      ")\n",
      "InferenceVisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (pre_logits): Identity()\n",
      "  (head): Linear(in_features=9216, out_features=1024, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "#import timm\n",
    "\n",
    "\n",
    "deit = deit_base_patch16_224(pretrained=True, use_top_n_heads=12,use_patch_outputs=False)\n",
    "deit.head = torch.nn.Linear(in_features=deit.head.in_features, out_features=classes_number)\n",
    "deit_model_path = './models/7_model_0.0001lr_40ep_256bs_12hs_62.748acc_0.9beta(11hrs)/model_24ep_1.2loss.pt'\n",
    "deit_state_dict = torch.load(deit_model_path)['state_dict']\n",
    "deit.load_state_dict(deit_state_dict)\n",
    "\n",
    "#cnn = timm.create_model('inception_resnet_v2', pretrained=True, num_classes=251)\n",
    "cnn = models.resnet50(pretrained=True) #.cuda()\n",
    "cnn.fc = torch.nn.Linear(in_features=cnn.fc.in_features, out_features=classes_number, bias=True)\n",
    "cnn_model_path = './models/8_Resnet_model_0.0001lr_10ep_256bs_12hs_60.81acc_0.9beta/model_3ep_1.3loss.pt'\n",
    "cnn_state_dict = torch.load(cnn_model_path)['state_dict']\n",
    "cnn.load_state_dict(cnn_state_dict)\n",
    "\n",
    "\n",
    "model = MyModel(deit=deit, cnn=cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/925 [00:00<?, ?it/s]/home/dmitry.demidov/.conda/envs/cv703/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 925/925 [19:52<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 1.4749220126800633\n",
      "Train Accuracy:66.947%\n",
      "Testing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:46<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4542030530988086\n",
      "Test Accuracy:63.515%\n",
      "Training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [19:43<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss: 0.859748171057523\n",
      "Train Accuracy:77.689%\n",
      "Testing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:46<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4907699736511983\n",
      "Test Accuracy:63.732%\n",
      "Training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [19:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss: 0.7506481002418017\n",
      "Train Accuracy:80.023%\n",
      "Testing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:41<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5195567269454067\n",
      "Test Accuracy:63.515%\n",
      "Training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 49/925 [01:01<18:38,  1.28s/it]"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train (device=device, model=model, criterion=criterion, optimizer=optimizer, \n",
    "        train_dataset=train_dataset, train_loader=train_loader, epoch=epoch, resnet=True)\n",
    "\n",
    "    test (device=device, model=model, criterion=criterion, \n",
    "        test_dataset=test_dataset, test_loader=test_loader, test_only = False, resnet=True) #, model_path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test only (optional):\n",
    "To check a specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing....\n",
      "Test only!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:26<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7027152970530142\n",
      "Test Accuracy:58.463%\n"
     ]
    }
   ],
   "source": [
    "# It is assumed that a model is defined already\n",
    "model_path = './models/model_3ep_1.4loss.pt'\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "test (device=device, model=model, criterion=criterion, \n",
    "    test_dataset=test_dataset, test_loader=test_loader, test_only = True, model_path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FocalLoss(torch.nn.Module):\n",
    "#     def __init__(self, alpha=1, gamma=2, reduce=True):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.reduce = reduce\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         BCE_loss = torch.nn.CrossEntropyLoss()(inputs, targets)\n",
    "\n",
    "#         pt = torch.exp(-BCE_loss)\n",
    "#         F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "#         if self.reduce:\n",
    "#             return torch.mean(F_loss)\n",
    "#         else:\n",
    "#             return F_loss\n",
    "\n",
    "# criterion = FocalLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms.CenterCrop(224) # instead of Resize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List\n",
    "* Change number of training epochs\n",
    "* Change number of class tokens e.g, use_top_n_heads=4, etc\n",
    "* New:\n",
    "* - Try focal loss (from Rushali)\n",
    "* - Try some transformations (Flipping, Rotation, CenterCrop ??)\n",
    "* - Combine resnet and DeiT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1a7d7175cab92eb6dbde117c0cc0b7f8055ecb32409ac704c7d8562db6b2b75"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('cv703': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}